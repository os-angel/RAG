{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c213e500",
   "metadata": {},
   "source": [
    "# **Module overview**\n",
    "\n",
    "This module covers everything about parsing and ingesting data for RAG systems, from basic text files to complex PDFs and databases. We'll use LangChain and explore each technique with practical and useful examples.\n",
    "\n",
    "Content:\n",
    "* Introduction to Data Ingestion\n",
    "    * Text Files (.txt)\n",
    "    * PDF documents\n",
    "    * Word documents\n",
    "    * CSV and excel files\n",
    "    * Json and structured data\n",
    "    * Web scrapping\n",
    "    * Databases (SQl)\n",
    "    * Audio and video transcripts\n",
    "* Advanced Techniques\n",
    "* Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa6cae",
   "metadata": {},
   "source": [
    "## **Data Ingestion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2cd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0d651",
   "metadata": {},
   "source": [
    "#### Understanding document structure in Langchain\n",
    "\n",
    "Important step previous applicate any technique.\n",
    "\n",
    "Metadata is really important for:\n",
    "- Filtering search results\n",
    "- Tracking document sources\n",
    "- Providing context in responses\n",
    "- Debugging and auditing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0875ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Content: This is the main text content that will embedded and searched\n",
      "Metadata: {'source': 'example.txt', 'page': 1, 'author': 'AngelO', 'date_created': '2025-08-23', 'custom_field': 'any_value'}\n"
     ]
    }
   ],
   "source": [
    "# Create a simple document\n",
    "doc = Document(\n",
    "    page_content = \"This is the main text content that will embedded and searched\",\n",
    "    metadata = {\n",
    "        \"source\":\"example.txt\",\n",
    "        \"page\":1,\n",
    "        \"author\":\"AngelO\",\n",
    "        \"date_created\":\"2025-08-23\",\n",
    "        \"custom_field\":\"any_value\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Document Structure\")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2debbe",
   "metadata": {},
   "source": [
    "### **Case 1: text files**\n",
    "\n",
    "The simple case for split documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f1532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "<class 'list'>\n",
      "[Document(metadata={'source': '../data/text_files/MCP.txt'}, page_content=\"Model Context Protocol (MCP): A Comprehensive IntroductionThe Model Context Protocol (MCP) represents one of the most significant innovations in the conversational artificial intelligence ecosystem, establishing an open standard that revolutionizes how large language models (LLMs) interact with external data sources and specialized tools. Developed by Anthropic in 2024, MCP emerges as a response to a critical need in the AI field: the ability to provide language models with secure, structured, and efficient access to information and functionalities that extend beyond their base training.Historical Context and the NeedDuring the early years of LLM development, one of the primary limitations was their static nature. These models, while extremely powerful in natural language processing and reasoning, were fundamentally constrained by the information present in their training data, with specific cutoff dates that left them outdated regarding recent events, specific enterprise data, or personal user information. This limitation gave rise to various ad-hoc solutions, such as specific API integrations, Retrieval-Augmented Generation (RAG) systems, and custom connectors, but each of these solutions required unique and non-scalable implementations.MCP emerges as an elegant solution to this problem, proposing a standardized protocol that allows any client application (such as Claude, ChatGPT, or any other AI interface) to connect uniformly with MCP servers that expose specific resources, whether they be databases, APIs, productivity tools, or any other type of external functionality.Architecture and Fundamental ComponentsMCP's architecture is based on a client-server philosophy that facilitates separation of concerns and enables extraordinary horizontal scalability. The protocol clearly defines three main components:MCP Clients are artificial intelligence applications that consume functionality exposed by servers. These clients, such as Claude Desktop, integrate the protocol to automatically discover available capabilities and present them coherently to the user. Client responsibilities include connection management, authentication when necessary, and interpretation of server responses to provide a smooth user experience.MCP Servers constitute the heart of the ecosystem, encapsulating specific logic for interacting with external resources. Each MCP server is essentially a specialized application that translates the capabilities of a specific system (such as a database, web service, or local tool) into the common language of the MCP protocol. These servers can be developed in any programming language and can handle everything from simple functionalities to complex operations requiring multiple steps or sophisticated authentication.The Communication Protocol itself defines the format and semantics of messages exchanged between clients and servers. Based on JSON-RPC 2.0, the protocol establishes standard methods for capability discovery, tool execution, resource access, and error handling, ensuring complete interoperability between implementations from different vendors.Resource Types and CapabilitiesMCP categorizes external functionalities into three main types of resources, each designed to address different use cases and interaction patterns:Resources represent data or information that can be read by the model. These can include text files, documents, web pages, database records, or any other type of structured or unstructured information. Resources in MCP are typically read-only and provide additional context that the model can use to generate more informed and accurate responses. A common example would be an MCP server that exposes the content of a corporate wiki or specific technical documentation.Tools constitute active functionalities that the model can execute to perform specific actions. Unlike resources, tools can modify the state of the external world, send emails, create files, perform calculations, or interact with third-party APIs. Tool definitions in MCP include not only the functionality itself but also detailed metadata about required parameters, expected data types, and possible side effects, allowing the model to make informed decisions about when and how to use each tool.Prompts represent reusable templates or context fragments that can be dynamically inserted into conversations. These prompts can include specialized instructions, format examples, or domain-specific context that helps the model respond more effectively in particular situations.Protocol Advantages and BenefitsMCP adoption introduces multiple significant advantages for both developers and end users. From a development perspective, MCP eliminates the need to create custom integrations for every client-service combination, dramatically reducing development and maintenance time. Developers can create a single MCP server that automatically works with all compatible clients, and conversely, clients can immediately benefit from all available MCP servers without requiring specific modifications.Standardization also brings unprecedented interoperability to the AI ecosystem. Organizations can develop internal MCP servers that expose their proprietary data and tools, knowing that these will work seamlessly with any MCP-compatible AI client. This creates a plugin-like ecosystem where functionality can be mixed and matched according to specific needs without vendor lock-in.\")]\n"
     ]
    }
   ],
   "source": [
    "# TextLoader - read a single file\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load a single file text\n",
    "loader = TextLoader(\"../data/text_files/MCP.txt\", encoding='utf-8')\n",
    "documents = loader.load()\n",
    "\n",
    "# Verify the loaders and documents\n",
    "print(f\"Loaded {len(documents)} document\")\n",
    "print(type(documents))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fde29b",
   "metadata": {},
   "source": [
    "It's possible load miltiples files from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be12e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1695.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory loaded with 2 files\n",
      "\n",
      " Document 1\n",
      "\n",
      " Source: ../data/text_files/AgenticAI.txt\n",
      "\n",
      " Lenght: 1361 characters\n",
      "\n",
      " Document 2\n",
      "\n",
      " Source: ../data/text_files/MCP.txt\n",
      "\n",
      " Lenght: 5436 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", # All the files with .txt extension\n",
    "    loader_cls=TextLoader, # Loader class to use\n",
    "    loader_kwargs= {'encoding':'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "\n",
    "print(f\"Directory loaded with {len(documents)} files\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\n Document {i+1}\")\n",
    "    print(f\"\\n Source: {doc.metadata['source']}\")\n",
    "    print(f\"\\n Lenght: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970d9f4",
   "metadata": {},
   "source": [
    "#### **Analysis of Text Files**\n",
    "\n",
    "Directory loader characteristics:\n",
    "- Advantages:\n",
    "    * Load multiple files at once\n",
    "    * Supports glob patterns\n",
    "    * Progress tracking\n",
    "    * Recursive directory scanning\n",
    "- Disadvantages:\n",
    "    * All files must be the same type\n",
    "    * Limited error handling per file\n",
    "    * Can be memory intensive for large directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8f259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4077d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
